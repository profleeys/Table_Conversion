import streamlit as st
from bs4 import BeautifulSoup
import numpy as np
import pandas as pd
import base64
import re

def create_download_link(data, filename):
    b64 = base64.b64encode(data).decode()  # å°‡æª”æ¡ˆæ•¸æ“šè½‰æ›ç‚º base64 ç·¨ç¢¼
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.presentationml.presentation;base64,{b64}" download="{filename}">é»æ­¤ä¸‹è¼‰</a>'
    return href

if __name__ == '__main__':
    st.title('è³‡æ–™è½‰æ›ç³»çµ±(html->xlsx)')

    file = st.file_uploader('è«‹é¸æ“‡è¦ä¸Šå‚³çš„æ–‡ä»¶:', type=['html'])
    
    openF = False
    
    if file is not None:
        html_content = file.read().decode('utf-8')
        #st.warning(html_content[:300])
        openF = True
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    if col1.button('è½‰æ›æª”æ¡ˆ') and openF == True:
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')

        # æ‰¾åˆ°æ‰€æœ‰çš„è¡¨æ ¼
        tables = soup.find_all('table')

        # å»ºç«‹ä¸€å€‹ç©ºçš„DataFrame
        combined_df = pd.DataFrame()

        extracted_city = 'Sheet1'

        # é€å€‹è™•ç†æ¯å€‹è¡¨æ ¼
        for table in tables:
            # å°‡è¡¨æ ¼è½‰æ›ç‚ºDataFrame
            df = pd.read_html(str(table))[0]
            
            if df.shape[0] < 3:
                pattern = r'ç¸£å¸‚åˆ¥ï¼š(.*?) è£½è¡¨æ—¥æœŸ'
                result = re.search(pattern, df.iloc[0][1][:100])
                if result:
                    extracted_city = result.group(1).replace(' ', '')
            else:
                # æª¢æŸ¥æ¯å€‹ row ä¸­çš„æ¯å€‹æ¬„ä½æ˜¯å¦è‡³å°‘æœ‰ä¸€å€‹æ•¸å­—
                #has_numeric_values = df.apply(lambda row: any(str(val).isdigit() or str(val) == 'åˆ è¨ˆ' or str(val) == 'ç”³å ±å¤§æ–¼æ­¸æˆ¶' for val in row if pd.notnull(val)), axis=1)
                has_numeric_values = df.apply(lambda row: any(str(val).isdigit() for val in row if pd.notnull(val)), axis=1)

                # ä¿ç•™è‡³å°‘æœ‰ä¸€å€‹æ¬„ä½çš„éç©ºå€¼ç‚ºæ•¸å­—çš„è³‡æ–™
                df = df[has_numeric_values]
                
                # å°‡DataFrameé€£æ¥åˆ°combined_df
                combined_df = pd.concat([combined_df, df])

        #combined_df = combined_df.drop(combined_df.index[0])  # åˆªé™¤ç¬¬ä¸€å€‹è¡Œ
        combined_df = combined_df.drop(combined_df.columns[0], axis=1).reset_index(drop=True)  # åˆªé™¤ç¬¬ä¸€å€‹åˆ—

        combined_df.iloc[:, 0] = combined_df.iloc[:, 0].fillna(method='ffill', axis=0)
        
        split_index = combined_df.shape[0] // 2
        table1 = combined_df.iloc[:split_index, :-1]
        table2 = combined_df.iloc[split_index:, :-3]
        
        table1.columns = ['å€é„‰','é‡Œæ‘','ç´ç¨…å–®ä½','åˆè¨ˆ','ç‡Ÿåˆ©æ‰€å¾—','åŸ·è¡Œæ¥­å‹™æ‰€å¾—','è–ªè³‡æ‰€å¾—','åˆ©æ¯æ‰€å¾—','ç§Ÿè³ƒåŠæ¬Šåˆ©é‡‘','è²¡ç”¢äº¤æ˜“æ‰€å¾—','æ©Ÿæœƒä¸­çæ‰€å¾—']
        table2.columns = ['å€é„‰','é‡Œæ‘','è‚¡åˆ©æ‰€å¾—','é€€è·æ‰€å¾—','å…¶ä»–æ‰€å¾—','ç¨¿è²»æ‰€å¾—','ç”³å ±å¤§æ–¼æ­¸æˆ¶','è–ªè³‡æ”¶å…¥','ç¨¿è²»æ”¶å…¥']

        # Perform a full outer join on columns 'A' and 'B'
        combined_df = pd.merge(table1, table2, on=['å€é„‰','é‡Œæ‘'], how='outer')

        # å°‡çµæœå¯«å…¥Excelæª”æ¡ˆ
        combined_df.to_excel('converted.xlsx', index=False, header=True, sheet_name=extracted_city)
        combined_df.to_csv('converted.csv', index=False, header=True)
        
        #with open('converted.xlsx', 'rb') as f:
        #    data = f.read()

        #é¡¯ç¤ºä¸‹è¼‰é€£çµ
        #st.markdown(create_download_link(data, 'converted.xlsx'), unsafe_allow_html=True)
        
        with open('converted.xlsx', 'rb') as my_file:
            col2.download_button(label = 'ğŸ“¥é»æ­¤ä¸‹è¼‰', data = my_file, file_name = 'converted.xlsx')    